{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "087b516c",
   "metadata": {},
   "source": [
    "# Step 00: download libs and backages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a60715",
   "metadata": {},
   "source": [
    "## Java for Standford POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8340a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting environment...\n",
      "Running locally\n",
      "Java is ready: java version \"1.8.0_202\"\n",
      "Proceeding with Stanford POS Tagger setup...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def is_running_in_colab():\n",
    "    \"\"\"\n",
    "    Check if the code is running in Google Colab environment\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if running in Colab, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "def is_running_in_jupyter():\n",
    "    \"\"\"\n",
    "    Check if the code is running in Jupyter notebook\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if running in Jupyter, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "        if 'IPKernelApp' in get_ipython().config:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def setup_java_environment():\n",
    "    \"\"\"\n",
    "    Setup Java environment automatically based on the platform\n",
    "    \n",
    "    Raises:\n",
    "        EnvironmentError: If Java setup fails locally\n",
    "    \"\"\"\n",
    "    \n",
    "    if is_running_in_colab():\n",
    "        print(\"Detected Google Colab environment - Setting up Java...\")\n",
    "        \n",
    "        # Install JDK in Colab\n",
    "        try:\n",
    "            print(\"Installing OpenJDK 8...\")\n",
    "            subprocess.run([\n",
    "                'apt-get', 'update', \n",
    "                '&&', 'apt-get', 'install', '-y', 'openjdk-8-jdk'\n",
    "            ], check=True, shell=True)\n",
    "            \n",
    "            # Set environment variables\n",
    "            java_home = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
    "            os.environ['JAVA_HOME'] = java_home\n",
    "            os.environ['PATH'] = f\"{java_home}/bin:{os.environ['PATH']}\"\n",
    "            \n",
    "            print(\"Java setup completed successfully in Colab\")\n",
    "            \n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Failed to install Java in Colab: {e}\")\n",
    "            raise EnvironmentError(\"Java installation failed in Colab\")\n",
    "        \n",
    "        # Check if Java is already installed locally\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                ['java', '-version'], \n",
    "                capture_output=True, \n",
    "                text=True, \n",
    "                timeout=10\n",
    "            )\n",
    "            if result.returncode == 0:\n",
    "                print(\"Java is already installed locally\")\n",
    "                # Extract and set JAVA_HOME if not set\n",
    "                if not os.environ.get('JAVA_HOME'):\n",
    "                    print(\"JAVA_HOME is not set. Please set it manually.\")\n",
    "            else:\n",
    "                raise EnvironmentError(\"Java is not installed locally\")\n",
    "                \n",
    "        except (FileNotFoundError, subprocess.TimeoutExpired):\n",
    "            # Running locally or in other environment\n",
    "            print(\"Java is not installed. \")\n",
    "            print(\"Please install Java manually:\")\n",
    "            print(\"   - Download JDK 8 from: https://adoptopenjdk.net/\")\n",
    "            print(\"   - Set JAVA_HOME environment variable\")\n",
    "            print(\"   - Add Java to your PATH\")\n",
    "            raise EnvironmentError(\n",
    "                \"Please install JDK 8 manually for local execution.\"\n",
    "            )\n",
    "\n",
    "\n",
    "def check_java_installation():\n",
    "    \"\"\"\n",
    "    Verify Java installation and version\n",
    "    \n",
    "    Returns:\n",
    "        dict: Installation status and version info\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['java', '-version'], \n",
    "            capture_output=True, \n",
    "            text=True, \n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            version_info = result.stderr.split('\\n')[0]\n",
    "            return {\n",
    "                'installed': True,\n",
    "                'version': version_info,\n",
    "                'environment': 'Colab' if is_running_in_colab() else 'Local'\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'installed': False,\n",
    "                'error': 'Java command failed',\n",
    "                'environment': 'Colab' if is_running_in_colab() else 'Local'\n",
    "            }\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        return {\n",
    "            'installed': False,\n",
    "            'error': 'Java not found in PATH',\n",
    "            'environment': 'Colab' if is_running_in_colab() else 'Local'\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'installed': False,\n",
    "            'error': str(e),\n",
    "            'environment': 'Colab' if is_running_in_colab() else 'Local'\n",
    "        }\n",
    "    \n",
    "def check_java_installation():\n",
    "    \"\"\"Check if Java is installed and get version\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(['java', '-version'], \n",
    "                              capture_output=True, \n",
    "                              text=True, \n",
    "                              timeout=10)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            version_line = result.stderr.split('\\n')[0]\n",
    "            return {'status': 'installed', 'version': version_line}\n",
    "        else:\n",
    "            return {'status': 'not installed'}\n",
    "            \n",
    "    except FileNotFoundError as e:\n",
    "        return {'status': 'not installed', 'error': str(e)}\n",
    "    except Exception as e:\n",
    "        return {'status': 'not installed', 'error': str(e)}\n",
    "\n",
    "def check_java_home():\n",
    "    \"\"\"Check JAVA_HOME environment variable\"\"\"\n",
    "    java_home = os.environ.get('JAVA_HOME')\n",
    "    if java_home:\n",
    "        print(f\"JAVA_HOME is set: {java_home}\")\n",
    "        \n",
    "        # Check if java exists in JAVA_HOME\n",
    "        java_path = os.path.join(java_home, 'bin', 'java')\n",
    "        if os.path.exists(java_path):\n",
    "            print(\"Java executable found in JAVA_HOME\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Java executable NOT found in JAVA_HOME\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"JAVA_HOME is not set\")\n",
    "        return False\n",
    "\n",
    "print(\"Detecting environment...\")\n",
    "\n",
    "# Check environment\n",
    "if is_running_in_colab():\n",
    "    print(\"Running in Google Colab\")\n",
    "else:\n",
    "    print(\"Running locally\")\n",
    "\n",
    "# Setup Java environment\n",
    "try:\n",
    "    setup_java_environment()\n",
    "    \n",
    "    # Verify installation\n",
    "    java_status = check_java_installation()\n",
    "    if java_status['status']:\n",
    "        print(f\"Java is ready: {java_status['version']}\")\n",
    "    else:\n",
    "        print(f\"Java check failed: {java_status['error']}\")\n",
    "        \n",
    "except EnvironmentError as e:\n",
    "    print(f\"Environment setup failed: {e}\")\n",
    "    print(\"Please setup Java manually and try again\")\n",
    "    raise Exception(e)\n",
    "\n",
    "# Continue with your Stanford POS Tagger code\n",
    "print(\"Proceeding with Stanford POS Tagger setup...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc635523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anyio==4.11.0 in .\\lib\\site-packages (from -r requirements.txt (line 1)) (4.11.0)\n",
      "Requirement already satisfied: argon2-cffi==25.1.0 in .\\lib\\site-packages (from -r requirements.txt (line 2)) (25.1.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings==25.1.0 in .\\lib\\site-packages (from -r requirements.txt (line 3)) (25.1.0)\n",
      "Requirement already satisfied: arrow==1.4.0 in .\\lib\\site-packages (from -r requirements.txt (line 4)) (1.4.0)\n",
      "Requirement already satisfied: asttokens==3.0.0 in .\\lib\\site-packages (from -r requirements.txt (line 5)) (3.0.0)\n",
      "Requirement already satisfied: async-lru==2.0.5 in .\\lib\\site-packages (from -r requirements.txt (line 6)) (2.0.5)\n",
      "Requirement already satisfied: attrs==25.4.0 in .\\lib\\site-packages (from -r requirements.txt (line 7)) (25.4.0)\n",
      "Requirement already satisfied: babel==2.17.0 in .\\lib\\site-packages (from -r requirements.txt (line 8)) (2.17.0)\n",
      "Requirement already satisfied: beautifulsoup4==4.14.2 in .\\lib\\site-packages (from -r requirements.txt (line 9)) (4.14.2)\n",
      "Requirement already satisfied: bleach==6.3.0 in .\\lib\\site-packages (from -r requirements.txt (line 10)) (6.3.0)\n",
      "Requirement already satisfied: certifi==2025.10.5 in .\\lib\\site-packages (from -r requirements.txt (line 11)) (2025.10.5)\n",
      "Requirement already satisfied: cffi==2.0.0 in .\\lib\\site-packages (from -r requirements.txt (line 12)) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer==3.4.3 in .\\lib\\site-packages (from -r requirements.txt (line 13)) (3.4.3)\n",
      "Requirement already satisfied: click==8.3.0 in .\\lib\\site-packages (from -r requirements.txt (line 14)) (8.3.0)\n",
      "Requirement already satisfied: colorama==0.4.6 in .\\lib\\site-packages (from -r requirements.txt (line 15)) (0.4.6)\n",
      "Requirement already satisfied: comm==0.2.3 in .\\lib\\site-packages (from -r requirements.txt (line 16)) (0.2.3)\n",
      "Requirement already satisfied: debugpy==1.8.17 in .\\lib\\site-packages (from -r requirements.txt (line 17)) (1.8.17)\n",
      "Requirement already satisfied: decorator==5.2.1 in .\\lib\\site-packages (from -r requirements.txt (line 18)) (5.2.1)\n",
      "Requirement already satisfied: defusedxml==0.7.1 in .\\lib\\site-packages (from -r requirements.txt (line 19)) (0.7.1)\n",
      "Requirement already satisfied: exceptiongroup==1.3.0 in .\\lib\\site-packages (from -r requirements.txt (line 20)) (1.3.0)\n",
      "Requirement already satisfied: executing==2.2.1 in .\\lib\\site-packages (from -r requirements.txt (line 21)) (2.2.1)\n",
      "Requirement already satisfied: farasapy==0.1.1 in .\\lib\\site-packages (from -r requirements.txt (line 22)) (0.1.1)\n",
      "Requirement already satisfied: fastjsonschema==2.21.2 in .\\lib\\site-packages (from -r requirements.txt (line 23)) (2.21.2)\n",
      "Requirement already satisfied: fqdn==1.5.1 in .\\lib\\site-packages (from -r requirements.txt (line 24)) (1.5.1)\n",
      "Requirement already satisfied: h11==0.16.0 in .\\lib\\site-packages (from -r requirements.txt (line 25)) (0.16.0)\n",
      "Requirement already satisfied: httpcore==1.0.9 in .\\lib\\site-packages (from -r requirements.txt (line 26)) (1.0.9)\n",
      "Requirement already satisfied: httpx==0.28.1 in .\\lib\\site-packages (from -r requirements.txt (line 27)) (0.28.1)\n",
      "Requirement already satisfied: idna==3.10 in .\\lib\\site-packages (from -r requirements.txt (line 28)) (3.10)\n",
      "Requirement already satisfied: ipykernel==7.1.0 in .\\lib\\site-packages (from -r requirements.txt (line 29)) (7.1.0)\n",
      "Requirement already satisfied: ipython==8.37.0 in .\\lib\\site-packages (from -r requirements.txt (line 30)) (8.37.0)\n",
      "Requirement already satisfied: ipywidgets==8.1.7 in .\\lib\\site-packages (from -r requirements.txt (line 31)) (8.1.7)\n",
      "Requirement already satisfied: isoduration==20.11.0 in .\\lib\\site-packages (from -r requirements.txt (line 32)) (20.11.0)\n",
      "Requirement already satisfied: jedi==0.19.2 in .\\lib\\site-packages (from -r requirements.txt (line 33)) (0.19.2)\n",
      "Requirement already satisfied: Jinja2==3.1.6 in .\\lib\\site-packages (from -r requirements.txt (line 34)) (3.1.6)\n",
      "Requirement already satisfied: joblib==1.5.2 in .\\lib\\site-packages (from -r requirements.txt (line 35)) (1.5.2)\n",
      "Requirement already satisfied: json5==0.12.1 in .\\lib\\site-packages (from -r requirements.txt (line 36)) (0.12.1)\n",
      "Requirement already satisfied: jsonpointer==3.0.0 in .\\lib\\site-packages (from -r requirements.txt (line 37)) (3.0.0)\n",
      "Requirement already satisfied: jsonschema==4.25.1 in .\\lib\\site-packages (from -r requirements.txt (line 38)) (4.25.1)\n",
      "Requirement already satisfied: jsonschema-specifications==2025.9.1 in .\\lib\\site-packages (from -r requirements.txt (line 39)) (2025.9.1)\n",
      "Requirement already satisfied: jupyter==1.1.1 in .\\lib\\site-packages (from -r requirements.txt (line 40)) (1.1.1)\n",
      "Requirement already satisfied: jupyter-console==6.6.3 in .\\lib\\site-packages (from -r requirements.txt (line 41)) (6.6.3)\n",
      "Requirement already satisfied: jupyter-events==0.12.0 in .\\lib\\site-packages (from -r requirements.txt (line 42)) (0.12.0)\n",
      "Requirement already satisfied: jupyter-lsp==2.3.0 in .\\lib\\site-packages (from -r requirements.txt (line 43)) (2.3.0)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in .\\lib\\site-packages (from -r requirements.txt (line 44)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.9.1 in .\\lib\\site-packages (from -r requirements.txt (line 45)) (5.9.1)\n",
      "Requirement already satisfied: jupyter_server==2.17.0 in .\\lib\\site-packages (from -r requirements.txt (line 46)) (2.17.0)\n",
      "Requirement already satisfied: jupyter_server_terminals==0.5.3 in .\\lib\\site-packages (from -r requirements.txt (line 47)) (0.5.3)\n",
      "Requirement already satisfied: jupyterlab==4.4.10 in .\\lib\\site-packages (from -r requirements.txt (line 48)) (4.4.10)\n",
      "Requirement already satisfied: jupyterlab_pygments==0.3.0 in .\\lib\\site-packages (from -r requirements.txt (line 49)) (0.3.0)\n",
      "Requirement already satisfied: jupyterlab_server==2.28.0 in .\\lib\\site-packages (from -r requirements.txt (line 50)) (2.28.0)\n",
      "Requirement already satisfied: jupyterlab_widgets==3.0.15 in .\\lib\\site-packages (from -r requirements.txt (line 51)) (3.0.15)\n",
      "Requirement already satisfied: lark==1.3.1 in .\\lib\\site-packages (from -r requirements.txt (line 52)) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe==3.0.3 in .\\lib\\site-packages (from -r requirements.txt (line 53)) (3.0.3)\n",
      "Requirement already satisfied: matplotlib-inline==0.2.1 in .\\lib\\site-packages (from -r requirements.txt (line 54)) (0.2.1)\n",
      "Requirement already satisfied: mistune==3.1.4 in .\\lib\\site-packages (from -r requirements.txt (line 55)) (3.1.4)\n",
      "Requirement already satisfied: nbclient==0.10.2 in .\\lib\\site-packages (from -r requirements.txt (line 56)) (0.10.2)\n",
      "Requirement already satisfied: nbconvert==7.16.6 in .\\lib\\site-packages (from -r requirements.txt (line 57)) (7.16.6)\n",
      "Requirement already satisfied: nbformat==5.10.4 in .\\lib\\site-packages (from -r requirements.txt (line 58)) (5.10.4)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in .\\lib\\site-packages (from -r requirements.txt (line 59)) (1.6.0)\n",
      "Requirement already satisfied: nltk==3.9.2 in .\\lib\\site-packages (from -r requirements.txt (line 60)) (3.9.2)\n",
      "Requirement already satisfied: notebook==7.4.7 in .\\lib\\site-packages (from -r requirements.txt (line 61)) (7.4.7)\n",
      "Requirement already satisfied: notebook_shim==0.2.4 in .\\lib\\site-packages (from -r requirements.txt (line 62)) (0.2.4)\n",
      "Requirement already satisfied: overrides==7.7.0 in .\\lib\\site-packages (from -r requirements.txt (line 63)) (7.7.0)\n",
      "Requirement already satisfied: packaging==25.0 in .\\lib\\site-packages (from -r requirements.txt (line 64)) (25.0)\n",
      "Requirement already satisfied: pandocfilters==1.5.1 in .\\lib\\site-packages (from -r requirements.txt (line 65)) (1.5.1)\n",
      "Requirement already satisfied: parso==0.8.5 in .\\lib\\site-packages (from -r requirements.txt (line 66)) (0.8.5)\n",
      "Requirement already satisfied: platformdirs==4.5.0 in .\\lib\\site-packages (from -r requirements.txt (line 67)) (4.5.0)\n",
      "Requirement already satisfied: prometheus_client==0.23.1 in .\\lib\\site-packages (from -r requirements.txt (line 68)) (0.23.1)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.52 in .\\lib\\site-packages (from -r requirements.txt (line 69)) (3.0.52)\n",
      "Requirement already satisfied: psutil==7.1.2 in .\\lib\\site-packages (from -r requirements.txt (line 70)) (7.1.2)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in .\\lib\\site-packages (from -r requirements.txt (line 71)) (0.2.3)\n",
      "Requirement already satisfied: pycparser==2.23 in .\\lib\\site-packages (from -r requirements.txt (line 72)) (2.23)\n",
      "Requirement already satisfied: Pygments==2.19.2 in .\\lib\\site-packages (from -r requirements.txt (line 73)) (2.19.2)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in .\\lib\\site-packages (from -r requirements.txt (line 74)) (2.9.0.post0)\n",
      "Requirement already satisfied: python-json-logger==4.0.0 in .\\lib\\site-packages (from -r requirements.txt (line 75)) (4.0.0)\n",
      "Requirement already satisfied: pywinpty==3.0.2 in .\\lib\\site-packages (from -r requirements.txt (line 76)) (3.0.2)\n",
      "Requirement already satisfied: PyYAML==6.0.3 in .\\lib\\site-packages (from -r requirements.txt (line 77)) (6.0.3)\n",
      "Requirement already satisfied: pyzmq==27.1.0 in .\\lib\\site-packages (from -r requirements.txt (line 78)) (27.1.0)\n",
      "Requirement already satisfied: referencing==0.37.0 in .\\lib\\site-packages (from -r requirements.txt (line 79)) (0.37.0)\n",
      "Requirement already satisfied: regex==2025.10.23 in .\\lib\\site-packages (from -r requirements.txt (line 80)) (2025.10.23)\n",
      "Requirement already satisfied: requests==2.32.5 in .\\lib\\site-packages (from -r requirements.txt (line 81)) (2.32.5)\n",
      "Requirement already satisfied: rfc3339-validator==0.1.4 in .\\lib\\site-packages (from -r requirements.txt (line 82)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator==0.1.1 in .\\lib\\site-packages (from -r requirements.txt (line 83)) (0.1.1)\n",
      "Requirement already satisfied: rfc3987-syntax==1.1.0 in .\\lib\\site-packages (from -r requirements.txt (line 84)) (1.1.0)\n",
      "Requirement already satisfied: rpds-py==0.28.0 in .\\lib\\site-packages (from -r requirements.txt (line 85)) (0.28.0)\n",
      "Requirement already satisfied: Send2Trash==1.8.3 in .\\lib\\site-packages (from -r requirements.txt (line 86)) (1.8.3)\n",
      "Requirement already satisfied: six==1.17.0 in .\\lib\\site-packages (from -r requirements.txt (line 87)) (1.17.0)\n",
      "Requirement already satisfied: sniffio==1.3.1 in .\\lib\\site-packages (from -r requirements.txt (line 88)) (1.3.1)\n",
      "Requirement already satisfied: soupsieve==2.8 in .\\lib\\site-packages (from -r requirements.txt (line 89)) (2.8)\n",
      "Requirement already satisfied: stack-data==0.6.3 in .\\lib\\site-packages (from -r requirements.txt (line 90)) (0.6.3)\n",
      "Requirement already satisfied: terminado==0.18.1 in .\\lib\\site-packages (from -r requirements.txt (line 91)) (0.18.1)\n",
      "Requirement already satisfied: tinycss2==1.4.0 in .\\lib\\site-packages (from -r requirements.txt (line 92)) (1.4.0)\n",
      "Requirement already satisfied: tomli==2.3.0 in .\\lib\\site-packages (from -r requirements.txt (line 93)) (2.3.0)\n",
      "Requirement already satisfied: tornado==6.5.2 in .\\lib\\site-packages (from -r requirements.txt (line 94)) (6.5.2)\n",
      "Requirement already satisfied: tqdm==4.67.1 in .\\lib\\site-packages (from -r requirements.txt (line 95)) (4.67.1)\n",
      "Requirement already satisfied: traitlets==5.14.3 in .\\lib\\site-packages (from -r requirements.txt (line 96)) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions==4.15.0 in .\\lib\\site-packages (from -r requirements.txt (line 97)) (4.15.0)\n",
      "Requirement already satisfied: tzdata==2025.2 in .\\lib\\site-packages (from -r requirements.txt (line 98)) (2025.2)\n",
      "Requirement already satisfied: uri-template==1.3.0 in .\\lib\\site-packages (from -r requirements.txt (line 99)) (1.3.0)\n",
      "Requirement already satisfied: urllib3==2.5.0 in .\\lib\\site-packages (from -r requirements.txt (line 100)) (2.5.0)\n",
      "Requirement already satisfied: wcwidth==0.2.14 in .\\lib\\site-packages (from -r requirements.txt (line 101)) (0.2.14)\n",
      "Requirement already satisfied: webcolors==25.10.0 in .\\lib\\site-packages (from -r requirements.txt (line 102)) (25.10.0)\n",
      "Requirement already satisfied: webencodings==0.5.1 in .\\lib\\site-packages (from -r requirements.txt (line 103)) (0.5.1)\n",
      "Requirement already satisfied: websocket-client==1.9.0 in .\\lib\\site-packages (from -r requirements.txt (line 104)) (1.9.0)\n",
      "Requirement already satisfied: widgetsnbextension==4.0.14 in .\\lib\\site-packages (from -r requirements.txt (line 105)) (4.0.14)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in .\\lib\\site-packages (from jupyterlab==4.4.10->-r requirements.txt (line 48)) (57.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Standford postagger already downloaed at ./content/drive/MyDrive/stanford-postagger-full, to download again, delete the download folder and run the code again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'c:\\pyvm\\anlp-py310\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\MK1349\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt\n",
    "\n",
    "# nltk punkt_lab\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Standord POS\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "standford_postagger_path = './content/drive/MyDrive/stanford-postagger-full'\n",
    "\n",
    "if not os.path.exists(standford_postagger_path):\n",
    "    print(\"Downloading Stanford POS Tagger...\")\n",
    "    url = \"https://nlp.stanford.edu/software/stanford-postagger-full-2018-10-16.zip\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    with open('./content/stanford-postagger-full.zip', 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    with zipfile.ZipFile('./content/stanford-postagger-full.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('./content/drive/MyDrive/')\n",
    "\n",
    "    os.rename('./content/drive/MyDrive/stanford-postagger-full-2018-10-16', standford_postagger_path)\n",
    "    print(\"Done!\")\n",
    "else:\n",
    "    print(f\"Standford postagger already downloaed at {standford_postagger_path},\\nTo download again, delete the download folder and run the code again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855225a3",
   "metadata": {},
   "source": [
    "# Step 01: Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0436dcb9",
   "metadata": {},
   "source": [
    "## download raw corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0081161e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 13:22:22,346 - ERROR - Error reading links file: [Errno 2] No such file or directory: 'data/raw/None'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics:\n",
      "  total_articles: 6572\n",
      "  articles_with_headline: 6498\n",
      "  articles_with_content: 6498\n",
      "  total_words: 2742273.0\n",
      "  average_article_length: 2522.6912896275776\n"
     ]
    }
   ],
   "source": [
    "# DO NOT RUN, data is already provided.\n",
    "from src.data_collection import DataCollector\n",
    "from config.settings import DATA_COLLECTION_CONFIG\n",
    "\n",
    "collector = DataCollector(base_dir=DATA_COLLECTION_CONFIG['base_dir'])\n",
    "\n",
    "# print(\"start links collecting..\")\n",
    "# news_links = collector.collect_links_from_altibbi(\n",
    "#     site_type=\"news\",\n",
    "#     max_pages=695, \n",
    "#     links_file=\"medical_news_links.txt\"\n",
    "# )\n",
    "\n",
    "# article_links = collector.collect_links_from_altibbi(\n",
    "#     site_type=\"articles\",\n",
    "#     max_pages=803, \n",
    "#     links_file=\"medical_articles_links.txt\"\n",
    "# )\n",
    "\n",
    "print(\"start_loading...\")\n",
    "corpus = collector.download_articles_content(\n",
    "    links_file=None,\n",
    "    corpus_file=\"medical_corpus.csv\"\n",
    ")\n",
    "\n",
    "stats = collector.get_corpus_stats(\"medical_corpus.csv\")\n",
    "print(\"statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a914ce",
   "metadata": {},
   "source": [
    "## preprocess corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69abd8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (6572, 3)\n",
      "Before cleaning - Sample texts:\n",
      "0    كشفت نتائج تجربة سريرية جديدة أن دواء جلوفادال...\n",
      "1    كشفت أدلة جديدة، مستندة إلى بيانات أكثر من 15,...\n",
      "2    دراسة رائدة كشفت أن مرضى السرطان الذين تلقوا ل...\n",
      "3    في إنجاز طبي بارز، كشفت دراسة سريرية واسعة قاد...\n",
      "4    حذّرت دراسة بريطانية واسعة من أن المشروبات الت...\n",
      "Name: articleBody, dtype: object\n",
      "\n",
      "After cleaning - Sample texts:\n",
      "0                                                                      كشفت نتائج تجربة سريرية جديدة أن دواء جلوفادالين بالإنجليزية التجريبي من شركة أظهر فعالية وأماناً كبيرين لمرضى باركنسون المتقدم. والأهم من ذلك أن الدواء نجح في تحسين الأعراض الحركية دون التسبب في الآثار الشائعة مثل الهلوسة وهبوط الضغط التي تُصاحب العلاجات الحالية. فعالية الدواء الجديد للباركنسون أظهرت نتائج المرحلة الثانية من تجربة التي شملت أكثر من 200 مريض يعانون من تذبذبات في الأعراض الحركية بشكل يومي أن المرضى الذين تلقوا جلوفادالين عن طريق الفم بالإضافة إلى جانب العلاج التقليدي لمدة 10 أسابيع شهدوا انخفاضاً أكبر في عدد ساعات التوقف وهي الفترات التي لا تعمل فيها الأدوية بشكل جيد وتعود الأعراض مقارنةً بأولئك الذين تلقوا علاجاً وهمياً محققين بذلك الهدف الأساسي للدراسة. بالإضافة إلى ذلك أبلغ عدد أكبر بكثير من المشاركين الذين تلقوا العلاج الفعال عن شعورهم بتحسن أفضل من قبل. آثار جانبية أقل لكن المفاجأة الكبرى كانت في ملف أمان الدواء الجديد تمثل في عدم تسجيل أي حالات من الآثار الجانبية المعروفة والناجمة عن زيادة الدوبامين في الدماغ مثل الهلوسة أو الارتباك أو انخفاض ضغط الدم أو الإغماء أو النعاس المفرط أثناء النهار. كما كان معدل التوقف عن تناول الدواء بسبب الآثار الجانبية منخفضاً جداً بنسبة 7.2 فقط. وقد تم تقديم هذه النتائج في 8 أكتوبر خلال المؤتمر الدولي لمرض باركنسون واضطرابات الحركة 2025. آلية عمل الدواء يرتبط مرض باركنسون بنقص إنتاج الدوبامين في الدماغ وهو الناقل العصبي المسؤول عن التحكم في الحركة. ويعمل غلوفادالين بطريقة مختلفة عن الأدوية التقليدية فهو منشّط إيجابي انتقائي لمستقبل 1 في الدماغ يُعزّز تأثير الدوبامين الطبيعي دون أن يحفزه بشكل مباشر. هذه الآلية المعروفة باسم التنشيط الجانبي بالإنجليزية تُقلل خطر الإفراط في تنشيط المستقبلات أو حدوث إشارات خاطئة مما يجعل الدواء أكثر أمانًا من منبهات الدوبامين التقليدية التي تسبب آثارًا جانبية شائعة مثل الحركات اللاإرادية والهلوسة. تفاصيل دراسة شملت الدراسة مشاركين تم تشخيصهم بمرض باركنسون لمدة 5 سنوات على الأقل يعانون من تذبذبات حركية يوميًا ويتناولون بالفعل دواء ليفودوبا أو أدوية مساعدة أخرى. تم توزيعهم عشوائيًا إلى ثلاث مجموعات دواء وهمي 70 مريضًا . غلوفادالين بجرعة منخفضة 70 مريضًا . غلوفادالين بجرعة مرتفعة 67 مريضًا . استمر العلاج لمدة 10 أسابيع مع متابعة دقيقة للأعراض اليومية وبيّنت النتائج انخفاضًا أكبر في وقت التوقف لدى مجموعتي الجرعتين المنخفضة والعالية مقارنةً بالدواء الوهمي بفارق وسطي بلغ 0.8 ساعة و0.45 ساعة يوميًا على التوالي. كما أبلغ 44 من المرضى الذين تلقوا الدواء بأنهم شعروا بتحسن واضح مقابل 22 فقط في المجموعة التي تلقت العلاج الوهمي. إضافةً لم تُظهر النتائج أي اختلاف يُذكر في معدل الآثار الجانبية بين المجموعات الثلاث أُبلغ عن الصداع كأثر جانبي غير خطير في 10 من الجرعة المنخفضة و6 من الجرعة العالية مقابل 4 في مجموعة الدواء الوهمي. كانت نسب الحركات اللاإرادية بالإنجليزية متقاربة في جميع المجموعات حوالي 5 6 . وأكد الباحثون أن هذه البيانات تُظهر أن الدواء آمن وجيد التحمل حتى بجرعات مرتفعة. الجيل القادم من العلاجات يعتقد الباحثون أن هذه البيانات تدعم جلوفادالين كعلاج فموي الأول في فئته لمرض باركنسون. كما أنهم يخططون لاختبار جرعات أعلى في دراسات مستقبلية لزيادة الفعالية مع الحفاظ على ملف الأمان. خبراء النتائج واعدة وتستحق المتابعة علقت الدكتورة جولي بيليتسيس رئيسة قسم جراحة الأعصاب في جامعة أريزونا واصفة الدراسة ب الواعدة وقالت إنها متحمسة لرؤية دراسات المرحلة التالية. وأكدت بيليتسيس التي لم تشارك في البحث أن الدواء يمكن أن يلبي حاجة مهمة نظراً لأن العلاجات الحالية تنطوي على مخاطر مثل خلل الحركة الشديد والهلوسة . وقالت اعتقدت أنها طريقة ذكية لمعالجة هذه المشكلات لم أرها من قبل . وأضافت أن هذا الانخفاض الطفيف في وقت التوقف بدا أنه يجعل الناس يشعرون بتحسن كبير وهو ما اعتبرته مقنعاً .\n",
      "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   كشفت أدلة جديدة مستندة إلى بيانات أكثر من 15,000 مشارك أن التمارين الهوائية الإيروبيك هي الطريقة الأفضل والأكثر أماناً لتقليل الألم وتحسين حركة مرضى خشونة الركبة الفصال العظمي . وعلى الرغم من أن التمارين الأخرى قد تساعد أيضاً إلا أنه لا شيء يتفوق على تمارين الإيروبيك في تحقيق نتائج ثابتة وطويلة الأمد . نظرة عامة حول الفصال العظمي يحدث الفصال العظمي عندما يتآكل الغضروف الذي يحمي نهايات العظام ما يؤدي إلى الألم والتورم وصعوبة الحركة. ورغم أنه يمكن أن يصيب أي مفصل إلا أنه أكثر شيوعاً في مفصل الركبة إذ يقدّر أن حوالي 30 من الأشخاص فوق سن 45 عامًا تظهر لديهم دلالات المرض في المفصل بحسب صور الأشعة السينية ونصفهم يعاني من أعراض شديدة تؤثر في حياتهم. تحليل شامل ل 217 تجربة سريرية تُعد التمارين الرياضية أحد العلاجات الرئيسية لخشونة المفاصل لكن لم يكن هناك توجيه واضح حول نوع التمارين الأفضل تحديدًا للركبة. لسد هذه الفجوة شرع الباحثون في تقييم فعالية وسلامة أنواع مختلفة من التمارين. استندت النتائج إلى تحليل 217 تجربة عشوائية نُشرت بين عامي 1990 2024 وشملت 15,684 مشاركاً. قارنت هذه التجارب بين العلاجات بالتمرين الشائعة منها تمارين الإيروبيك الهوائية . تمارين المرونة. تمارين القوة. تمارين التنسيق العصبي الحركي. تمارين الجسم والعقل مثل اليوغا والتاي تشي . التمارين المختلطة. كانت المقاييس الرئيسية محل الاهتمام هي الألم والوظيفة وأداء المشي وجودة الحياة وتم تقييمها على المدى القصير 4 أسابيع والمتوسط 12 أسبوعاً والطويل 24 أسبوعاً . النتائج الإيروبيك أولاً وبفارق واضح وجدت الدراسة الحديثة التي نشرتها اليوم المجلة الطبية البريطانية أنه بالنسبة لمرضى الفُصال العظمي في الركبة فإن الأنشطة الهوائية مثل المشي أو ركوب الدراجات أو السباحة من المرجح أن تكون أفضل التمارين لتحسين الألم والوظيفة وأداء المشي وجودة الحياة. وقال الباحثون إنه على الرغم من أن التمارين الأخرى قد تقدم فوائد تكميلية للمرضى إلا أنه لا ينبغي لها أن تحل محل التمارين الهوائية كاستراتيجية علاجية رئيسية. ورغم اختلاف الأنواع لم تُسجّل أي آثار جانبية خطيرة أو زيادة في المخاطر للمرضى الممارسين مما يؤكد أن أداء التمارين بشكل منظم خيار آمن تمامًا. توصيات الباحثين يؤكد الباحثون أن نتائجهم تمثل أوسع وأحدث تحليل حتى الآن حول فعالية التمارين في إدارة خشونة الركبة. ويُوصون ب التمارين الهوائية كخيار علاجي أول للمرضى خصوصًا لتحسين الحركة وتقليل الألم مع إمكانية ممارسة أنواع أخرى من التمارين إلى جانبها. وفي حال كان المريض غير قادر على أداء التمارين الهوائية بسبب ظروف خاصة فإن أي نشاط بدني منظم يظل ذا فائدة. استشر الأطباء الآن وأنت في المنزل من خلال حجز موعد عن بعد لدى موقع الطبي.\n",
      "2    دراسة رائدة كشفت أن مرضى السرطان الذين تلقوا لقاح كوفيد 19 بتقنية في غضون 100 يوم من بدء العلاج المناعي عاشوا لفترة أطول بكثير مقارنة بالذين لم يتلقوا اللقاح. ويلمح هذا الاكتشاف الذي قاده باحثون من جامعة فلوريدا ومركز إم دي أندرسون للسرطان بجامعة تكساس إلى حقبة جديدة محتملة من اللقاحات المعززة للمناعة والتي قد تُحدث ثورة في علاج أنواع متعددة من السرطان. وقُدمت النتائج في المؤتمر السنوي للجمعية الأوروبية لطب الأورام لعام 2025 في برلين. مضاعفة معدلات البقاء حللت الدراسة بيانات أكثر من 1000 مريض يعانون من سرطان الرئة ذو الخلايا غير الصغيرة المرحلة 3 و 4 و سرطان الجلد النقيلي المنتشر والذين تلقوا العلاج المناعي بين عامي 2019 2023. وأظهرت النتائج أن المرضى الذين تلقوا لقاح كورونا مثل لقاح فايزر أو موديرنا خلال فترة لا تتجاوز 100 يوم من بدء العلاج المناعي حققوا معدلات بقاء أطول بنسب تصل إلى الضعف مقارنة بغيرهم. فقد ارتفع متوسط البقاء على قيد الحياة بين مرضى سرطان الرئة من 20.6 شهرًا إلى 37.3 شهرًا بينما ازداد لدى مرضى الميلانوما من 26.7 شهرًا إلى نحو 40 شهرًا مع بقاء بعض المرضى على قيد الحياة حتى نهاية الدراسة ما يشير إلى أن التأثير قد يكون أقوى مما هو مُعلن. من اللافت أن اللقاحات غير القائمة على مثل لقاحات الإنفلونزا أو الالتهاب الرئوي لم تُظهر أي تحسّن في معدلات البقاء مما يشير إلى أن التقنية الجينية المستخدمة في لقاح كوفيد هي التي تلعب الدور المناعي الحاسم. كيف يعمل لقاح كورونا على إيقاظ الجهاز المناعي يرى الباحثون أن لقاح كوفيد 19 ربما يعمل بطريقة تشبه إطلاق إشارة إنذار داخل الجسم مما ينشّط الخلايا المناعية ويعيد توجيهها من الورم إلى العقد اللمفاوية فتتعزز قدرة جهاز المناعة على مهاجمة الخلايا السرطانية. وكان الفريق قد لاحظ سابقًا أن تنشيط جهاز المناعة دون استهداف بروتين محدد يمكن أن يولد استجابة قوية ضد الأورام تمامًا كما يحدث عند التصدي للفيروسات. حيث تقول هذه الفرضية إن اللقاح نفسه لا يحتاج لأن يكون موجّهًا ضد السرطان مباشرة بل يكفي أن يوقظ جهاز المناعة ويعيد توازنه مما يمنحه قدرة أفضل على التعرّف على الخلايا الخبيثة ومهاجمتها ويبدو أن لقاح كوفيد 19 بتقنية يؤدي دوراً مشابهاً. وأوضح الدكتور إلياس أخصائي أورام الأطفال في جامعة فلوريدا والمشرف على الدراسة أن هذه الملاحظة تمثل لحظة فارقة بعد أكثر من عقد من الأبحاث حول اللقاحات القائمة على تقنية . وقال عندما تعطي لقاح فإنه يعمل كشعلة إنذار تبدأ في نقل كل هذه الخلايا المناعية من المناطق السيئة مثل الورم إلى المناطق الجيدة مثل العقد اللمفاوية حيث يتم تفعيلها لمهاجمة السرطان. هذا المزيج الذي يشبه اللكمة المزدوجة لقاح العلاج المناعي نجح في تحويل الأورام غير المستجيبة في نماذج الفئران إلى أورام مستجيبة مما أحبط نمو الورم. ثورة في علاج الأورام علّق الدكتور جيف كولر العالم البارز في تقنية بجامعة جونز هوبكنز غير المشارك بالدراسة بأن النتائج تظهر مدى قوة أدوية وأنها تُحدث ثورة في علاجنا للسرطان مشيراً إلى أن هذه إحدى الطرق الفريدة وغير المتوقعة التي تستمر بها تقنيات مواجهة كوفيد 19 في إنقاذ الأرواح. أما ا لدكتور دوين ميتشل مدير معهد العلوم الإكلينيكية بجامعة فلوريدا فأكد أن هذه النتائج رغم كونها مبدئية تستحق متابعة عاجلة عبر تجارب سريرية واسعة لتأكيد الفاعلية والآلية. دراسة مبدئية والتجارب السريرية هي الفيصل يستعد الباحثون لإطلاق تجربة سريرية كبرى ضم ن شبكة التي تضم مستشفيات ومراكز أبحاث في ولايات أمريكية عدة من بينها فلوريدا وجورجيا وأركنساس وكاليفورنيا. وتهدف هذه التجربة إلى اختبار ما إذا كان يمكن استخدام لقاح كمحفّز مناعي عام إلى جانب أدوية العلاج المناعي المختلفة ما قد يُحدث نقلة في رعاية مرضى السرطان المتقدم. وخلص الباحثون إلى أنه إذا تم تأكيد هذه النتائج فإنها ستفتح إمكانيات لا حصر لها وقد يعني توفير وقت ثمين للمرضى الذين يعانون من سرطانات متقدمة حتى لو كانت الزيادة في فرص البقاء 5 أو 10 فقط. استفسر عن أي شيء يخص صحتك من خلال الاستشارة السهلة الآن مع موقع الطبي.\n",
      "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    في إنجاز طبي بارز كشفت دراسة سريرية واسعة قادها باحثون من مركز سيدارز سايناي الأمريكي أن مزيجًا دوائيًا جديدًا نجح في خفض خطر الوفاة بين المرضى المصابين بسرطان البروستاتا المتكرر بنسبة تصل إلى 40 مقارنة بالعلاج التقليدي وحده. ما هو سرطان البروستاتا المتكرر يُعرَّف سرطان البروستاتا المتكرر بأنه عودة السرطان بعد تلقي المريض علاجاً أولياً مثل الجراحة أو الإشعاع كان يهدف إلى الشفاء التام. وقد يحدث ذلك لأحد سببين رئيسيين بقاء خلايا سرطانية صغيرة غير مكتشفة بعد العلاج الأول تنمو ببطء لتظهر مجددًا بعد فترة. أو أن السرطان كان في مرحلة متقدمة أكثر مما ظن الأطباء في البداية حيث انتشرت خلايا دقيقة إلى خارج البروستاتا مثل العقد اللمفاوية أو العظام ولم ترصدها الفحوصات الأولية. في كلتا الحالتين يصعب السيطرة على المرض عندما يعود بشكل عدواني ما يستدعي البحث عن علاجات جديدة قادرة على إطالة عمر المرضى وتحسين نوعية حياتهم. العلاج المزدوج أمل جديد لمرضى السرطان المتكرر الدراسة التي نُشرت في مجلة وعُرضت خلال مؤتمر الجمعية الأوروبية لطب الأورام في برلين ركزت على مزيج من العلاج الهرموني التقليدي مع دواء يُعرف باسم إنزالوتاميد بالإنجليزية . وشملت التجربة أكثر من 1000 مريض من 244 مركزًا طبيًا في 17 دولة جميعهم مصابون بما يُعرف ب سرطان البروستاتا المتكرر عالي الخطورة وهو النوع الذي يشهد فيه المرضى ارتفاعًا سريعًا في مستوى مستضد البروستاتا النوعي بعد الجراحة أو الإشعاع مما يشير إلى عودة النشاط السرطاني واحتمال انتشاره إلى العظام أو العمود الفقري. نتائج التجربة الحاسمة تم تقسيم المرضى عشوائياً إلى 3 مجموعات مجموعة تلقت العلاج الهرموني فقط. مجموعة تلقت دواء إنزالوتاميد فقط. مجموعة ثالثة تلقت العلاج المزدوج. وبعد 8 سنوات من المتابعة أظهرت النتائج أن خطر الوفاة انخفض بنسبة 40.3 لدى من تلقوا العلاج المزدوج مقارنة بالمجموعتين الأخريين كما أظهرت البيانات تحسنًا واضحًا في السيطرة على تقدم المرض ومنع انتشاره إلى الأعضاء الحيوية. تغيير جذري بعد 30 عاماً قال الدكتور ستيفن فريدلاند مدير مركز الأبحاث المتكاملة في السرطان ونمط الحياة بمركز سيدارز سايناي للسرطان والباحث المشارك الرئيسي في الدراسة بعد العلاج الأولي يرى بعض المرضى عودة سرطان البروستاتا لديهم بطريقة عدوانية ويكونون معرضين لخطر انتشار المرض بسرعة . وأضاف العلاج الهرموني وهو ما كنا نقدمه للمرضى لمدة 30 عاماً لم يحسن معدلات البقاء على قيد الحياة ولم يفعل أي شيء آخر ذلك. وهذا ما يجعل هذه النتائج بمثابة تغيير جذري حقيقي . نحو معيار جديد لعلاج سرطان البروستاتا المتكرر أوضح الفريق البحثي أن دواء إنزالوتاميد كان قد حصل سابقًا على موافقة إدارة الغذاء والدواء الأمريكية للاستخدام في حالات معينة من سرطان البروستاتا لكن النتائج الجديدة قد تفتح الباب لاعتماده رسميًا كعلاج معياري مزدوج في حالات الانتكاس بعد الجراحة أو الإشعاع. بدوره قال الدكتور هيونغ كيم رئيس قسم جراحة المسالك البولية في سيدارز سايناي تحدد هذه النتائج المهمة علاجاً يطيل عمر الرجال المصابين بسرطان البروستاتا العدواني وستغير طريقة رعايتنا لمرضانا . تمثل هذه النتائج خطوة مهمة نحو تحسين فرص البقاء لآلاف الرجال حول العالم الذين يعانون من سرطان البروستاتا المتكرر عالي الخطورة.\n",
      "4                                                                                                                                                                                                                                                                                                                                                                                   حذّرت دراسة بريطانية واسعة من أن المشروبات التي تحتوي على المحليات الصناعية أو المعروفة بمشروبات الدايت ليست بالضرورة خيارًا صحيًا بل قد تزيد من خطر الإصابة بأمراض الكبد الدهنية أكثر من المشروبات السكرية العادية. المحليات الصناعية تتفوق بالضرر الدراسة التي استندت إلى بيانات 123,788 شخصًا من قاعدة بيانات البنك الحيوي البريطاني وتابعتهم لأكثر من 10 سنوات كشفت أن تناول علبة واحدة يوميًا من المشروبات منخفضة أو خالية السكر يرتبط بزيادة خطر الإصابة بمرض الكبد الدهني المرتبط بالخلل الأيضي بنسبة 60 في حين ارتبطت المشروبات السكرية بزيادة الخطر بنسبة 50 . وعُرضت النتائج خلال مؤتمر أسبوع أمراض الجهاز الهضمي الأوروبي 2025 في برلين حيث أكدت الباحثة ليهي ليو من جامعة سوتشو الصينية أن هذه النتائج تتحدى التصور الشائع بأن مشروبات الدايت غير ضارة داعيةً إلى إعادة التفكير في دورها ضمن النظام الغذائي خصوصًا مع تزايد معدلات أمراض الكبد عالميًا. الكبد الدهني.. وباء عالمي صامت يؤثر مرض الكبد الدهني المرتبط بالخلل الأيضي حالياً على ما يقدر بنحو 38 من سكان العالم وأصبح سبباً رئيسياً ل تشمع الكبد و سرطان الكبد والوفيات المرتبطة بأمراض الكبد. رغم أن تعديل نمط الحياة هو الأساس في الوقاية والعلاج إلا أن معظم الإرشادات الطبية ركزت سابقًا على تقليل المشروبات السكرية فقط دون التطرق بوضوح للمشروبات الصناعية التحلية. نتائج الدراسة بعد تحليل النتائج تبين أن الذين تناولوا أكثر من مشروب واحد من الدايت يوميًا كانوا أكثر عرضة للإصابة بأمراض الكبد بنسبة 60 . والأخطر من ذلك أن استهلاك مشروبات الدايت ارتبط أيضاً بزيادة خطر الإصابة بمضاعفات الكبد الحادة مثل التليف أو الفشل الكبدي بنسبة 55 في حين لم تُظهر المشروبات السكرية ارتباطاً كبيراً بهذه المضاعفات بعد ضبط المتغيرات. كما ارتبط كلا النوعين بزيادة محتوى الدهون في الكبد حيث تسببت المشروبات السكرية بزيادة 5 في دهون الكبد بينما تسببت مشروبات الدايت بزيادة 7 مقارنة بغير المستهلكين. لماذا تضر المحليات الصناعية بالكبد فسرت ليو الآليات المحتملة مشيرة إلى أن المشروبات السكرية تسبب ارتفاعاً سريعاً في جلوكوز الدم والإنسولين مما يعزز زيادة الوزن وتراكم الدهون في الكبد. أما المشروبات المحلاة صناعياً الدايت فقد تؤثر على صحة الكبد عن طريق تغيير الميكروبيوم المعوي بكتيريا الأمعاء وتعطيل الشعور بالامتلاء وزيادة الرغبة الشديدة في تناول السكريات وحتى تحفيز إفراز الإنسولين مما يؤدي في النهاية إلى نتائج مشابهة أو أسوأ. الماء هو البديل الأفضل يؤكد الخبراء أن الماء يبقى الخيار الأكثر أمانًا وصحة كونه لا يحمّل الكبد أي عبء ويساعد على طرد السموم وترطيب الجسم. كما أشارت الدراسة أن استبدال أي من نوعي المشروبات بالماء يقلل من خطر الإصابة بمرض الكبد الدهني بنسبة 12.8 عند استبدال المشروبات السكرية وبنسبة 15.2 عند استبدال مشروبات الدايت. آراء الخبراء حان وقت الحذر من الدايت من جهته علق الدكتور سوجيت جاناردان مدير برنامج أمراض الكبد الدهني في جامعة راش الأمريكية قائلاً إن النتائج يجب أن تدفعنا بالتأكيد إلى التوقف عن الفكرة الشائعة بأن مشروبات الدايت أكثر صحة . وأضاف أن من المهم التأكد من عوامل أخرى قد تؤثر في النتائج مثل أن يكون الأشخاص الذين يتناولون هذه المشروبات أصلاً أكثر عرضة للأمراض الأيضية أو السمنة ما قد يفسّر جزئيًا ارتفاع المخاطر لديهم. ومع ذلك أشار إلى أن الرسالة الأوضح من هذه الدراسة هي أن استبدال المشروبات الغازية بالماء يقلل خطر الإصابة بالكبد الدهني. استفسر عن أفضل طرق علاج مرض الكبد الدهني وأنت في منزلك من خلال خدمة الاستشارات الطبية عن بعد مع الطبي\n",
      "Name: articleBody, dtype: object\n",
      "\n",
      "Cleaning Statistics:\n",
      "Total articles: 6572\n",
      "Articles with content: 6498\n",
      "Average article length: 2336 characters\n",
      "\n",
      "Before/After Comparison:\n",
      "\n",
      "--- Example 1 ---\n",
      "BEFORE: كشفت نتائج تجربة سريرية جديدة أن دواء جلوفادالين (بالإنجليزية: Glovadalen) التجريبي، من شركة UCB، أظهر فعالية وأماناً كبيرين لمرضى باركنسون المتقدم. والأهم من ذلك، أن الدواء نجح في تحسين الأعراض الحرك...\n",
      "AFTER:  كشفت نتائج تجربة سريرية جديدة أن دواء جلوفادالين بالإنجليزية التجريبي من شركة أظهر فعالية وأماناً كبيرين لمرضى باركنسون المتقدم. والأهم من ذلك أن الدواء نجح في تحسين الأعراض الحركية دون التسبب في الآث...\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Example 2 ---\n",
      "BEFORE: كشفت أدلة جديدة، مستندة إلى بيانات أكثر من 15,000 مشارك، أن التمارين الهوائية (الإيروبيك) هي الطريقة الأفضل والأكثر أماناً لتقليل الألم، وتحسين حركة مرضى خشونة الركبة (الفصال العظمي). وعلى الرغم من أن...\n",
      "AFTER:  كشفت أدلة جديدة مستندة إلى بيانات أكثر من 15,000 مشارك أن التمارين الهوائية الإيروبيك هي الطريقة الأفضل والأكثر أماناً لتقليل الألم وتحسين حركة مرضى خشونة الركبة الفصال العظمي . وعلى الرغم من أن التما...\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Example 3 ---\n",
      "BEFORE: دراسة رائدة كشفت أن مرضى السرطان الذين تلقوا لقاح كوفيد-19 (بتقنية mRNA) في غضون 100 يوم من بدء العلاج المناعي، عاشوا لفترة أطول بكثير مقارنة بالذين لم يتلقوا اللقاح. ويلمح هذا الاكتشاف، الذي قاده باح...\n",
      "AFTER:  دراسة رائدة كشفت أن مرضى السرطان الذين تلقوا لقاح كوفيد 19 بتقنية في غضون 100 يوم من بدء العلاج المناعي عاشوا لفترة أطول بكثير مقارنة بالذين لم يتلقوا اللقاح. ويلمح هذا الاكتشاف الذي قاده باحثون من جا...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./data/raw/medical_corpus.csv\")\n",
    "\n",
    "from src.text_processor import *\n",
    "\n",
    "# Apply processing to the dataframe\n",
    "pdf = df.copy()\n",
    "\n",
    "print(\"Original data shape:\", pdf.shape)\n",
    "print(\"Before cleaning - Sample texts:\")\n",
    "print(df['articleBody'].head())\n",
    "\n",
    "# Apply cleaning using the pipeline function (more efficient)\n",
    "pdf['articleBody'] = pdf['articleBody'].apply(clean_text_pipeline)\n",
    "\n",
    "print(\"\\nAfter cleaning - Sample texts:\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(pdf['articleBody'].head())\n",
    "\n",
    "# Display statistics\n",
    "print(f\"\\nCleaning Statistics:\")\n",
    "print(f\"Total articles: {len(pdf)}\")\n",
    "print(f\"Articles with content: {pdf['articleBody'].str.len().gt(0).sum()}\")\n",
    "print(f\"Average article length: {pdf['articleBody'].str.len().mean():.0f} characters\")\n",
    "\n",
    "# Show some examples of before/after cleaning\n",
    "print(\"\\nBefore/After Comparison:\")\n",
    "for i in range(min(3, len(df))):\n",
    "    print(f\"\\n--- Example {i+1} ---\")\n",
    "    print(\"BEFORE:\", df['articleBody'].iloc[i][:200] + \"...\" if len(str(df['articleBody'].iloc[i])) > 200 else df['articleBody'].iloc[i])\n",
    "    print(\"AFTER: \", pdf['articleBody'].iloc[i][:200] + \"...\" if len(str(pdf['articleBody'].iloc[i])) > 200 else pdf['articleBody'].iloc[i])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1c8901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved at: data/processed/medical_corpus_processed.json\n",
      "6572 were saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.makedirs(\"data/processed\", exist_ok=True)\n",
    "\n",
    "try:\n",
    "    pdf.to_json(\"data/processed/medical_corpus_processed.json\", orient='records', force_ascii=False, indent=2)\n",
    "    print(\"Data saved at: data/processed/medical_corpus_processed.json\")\n",
    "    \n",
    "    \n",
    "    print(f\"{len(pdf)} were saved!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc10910d",
   "metadata": {},
   "source": [
    "# Step 02: Relations and Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4526332c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\MK1349\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6572 articles were loaded.\n",
      "Stanford POS Tagger initialized successfully\n",
      "Start extracting realtions from 6572 articles...\n",
      "article 100 processed...\n",
      "article 200 processed...\n",
      "article 300 processed...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Tuple, Any\n",
    "from nltk.tag import StanfordPOSTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "class RelationExtractor:\n",
    "    def __init__(self, base_dir: str = \"data\"):\n",
    "        self.base_dir = base_dir\n",
    "        self.setup_directories()\n",
    "        self.tagger = ArabicPOSTagger()\n",
    "        self.templates = self.load_templates()\n",
    "        \n",
    "    def setup_directories(self):\n",
    "        \"\"\"إنشاء المجلدات المطلوبة\"\"\"\n",
    "        os.makedirs(f\"{self.base_dir}/results\", exist_ok=True)\n",
    "        os.makedirs(f\"{self.base_dir}/processed\", exist_ok=True)\n",
    "        \n",
    "    def load_templates(self) -> Dict[str, List[str]]:\n",
    "        \n",
    "        templates = {\n",
    "            \"يعالج\": [\n",
    "                r\"يستخدم\\s+(\\S+)\\s+في\\s+علاج\\s+(\\S+)\",\n",
    "                r\"يعالج\\s+(\\S+)\\s+مرض\\s+(\\S+)\",\n",
    "                r\"يشفي\\s+(\\S+)\\s+من\\s+(\\S+)\",\n",
    "                r\"يداوي\\s+(\\S+)\\s+حالة\\s+(\\S+)\",\n",
    "                r\"يعالج\\s+(\\S+)\\s+الاصابة\\s+ب\\s+(\\S+)\",\n",
    "                r\"يشفي\\s+(\\S+)\\s+من\\s+داء\\s+(\\S+)\",\n",
    "                r\"يقضي\\s+(\\S+)\\s+على\\s+(\\S+)\",\n",
    "                r\"يزيل\\s+(\\S+)\\s+اعراض\\s+(\\S+)\",\n",
    "                r\"يخلص\\s+(\\S+)\\s+من\\s+(\\S+)\",\n",
    "                r\"يحارب\\s+(\\S+)\\s+مرض\\s+(\\S+)\",\n",
    "                r\"يواجه\\s+(\\S+)\\s+المرض\\s+(\\S+)\",\n",
    "                r\"يسيطر\\s+(\\S+)\\s+على\\s+(\\S+)\",\n",
    "                r\"يحد\\s+(\\S+)\\s+من\\s+انتشار\\s+(\\S+)\",\n",
    "                r\"يوقف\\s+(\\S+)\\s+تطور\\s+(\\S+)\",\n",
    "                r\"يمنع\\s+(\\S+)\\s+تفاقم\\s+(\\S+)\",\n",
    "                r\"يخفف\\s+(\\S+)\\s+من\\s+(\\S+)\",\n",
    "                r\"يقلل\\s+(\\S+)\\s+حدة\\s+(\\S+)\",\n",
    "                r\"يحتوي\\s+(\\S+)\\s+على\\s+(\\S+)\",\n",
    "                r\"يستهدف\\s+(\\S+)\\s+مرض\\s+(\\S+)\",\n",
    "                r\"يعمل\\s+(\\S+)\\s+ضد\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+دواء\\s+ل\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+علاج\\s+فعال\\s+ل\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+من\\s+ادوية\\s+(\\S+)\",\n",
    "                r\"علاج\\s+(\\S+)\\s+يكون\\s+ب\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+من\\s+العلاجات\\s+الناجحة\\s+ل\\s+(\\S+)\",\n",
    "                r\"الدواء\\s+(\\S+)\\s+مخصص\\s+ل\\s+(\\S+)\",\n",
    "                r\"العقار\\s+(\\S+)\\s+مصمم\\s+ل\\s+(\\S+)\",\n",
    "                r\"العلاج\\s+(\\S+)\\s+موجه\\s+ل\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+من\\s+الادوية\\s+المضادة\\s+ل\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+من\\s+العلاجات\\s+المتعارفة\\s+ل\\s+(\\S+)\",\n",
    "                r\"العلاج\\s+ب\\s+(\\S+)\\s+ل\\s+(\\S+)\",\n",
    "                r\"استخدام\\s+(\\S+)\\s+في\\s+(\\S+)\",\n",
    "                r\"تناول\\s+(\\S+)\\s+ل\\s+(\\S+)\",\n",
    "                r\"وصفة\\s+(\\S+)\\s+لمرضى\\s+(\\S+)\",\n",
    "                r\"جرعة\\s+(\\S+)\\s+لعلاج\\s+(\\S+)\",\n",
    "                r\"مصل\\s+(\\S+)\\s+ضد\\s+(\\S+)\",\n",
    "                r\"مضاد\\s+(\\S+)\\s+ل\\s+(\\S+)\",\n",
    "                r\"حبوب\\s+(\\S+)\\s+ل\\s+(\\S+)\",\n",
    "                r\"كبسولات\\s+(\\S+)\\s+ل\\s+(\\S+)\",\n",
    "                r\"حقن\\s+(\\S+)\\s+ل\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+فعال\\s+ضد\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+ناجع\\s+في\\s+معالجة\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+مفيد\\s+لمرضى\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+يحدث\\s+تحسنا\\s+في\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+يساعد\\s+في\\s+شفاء\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+يساهم\\s+في\\s+علاج\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+يعين\\s+في\\s+التغلب\\s+على\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+يدعم\\s+علاج\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+يشارك\\s+في\\s+معالجة\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+يسرع\\s+شفاء\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+يحسن\\s+حالة\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+ينعش\\s+مرضى\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+ينشط\\s+علاج\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+يفيد\\s+في\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+يجدي\\s+نفعا\\s+في\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+يمنح\\s+الشفاء\\s+من\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+يضمن\\s+علاج\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+يؤمن\\s+الشفاء\\s+من\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+يوفر\\s+علاجا\\s+ل\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+يحتوي\\s+علاج\\s+(\\S+)\",\n",
    "                r\"باستخدام\\s+(\\S+)\\s+يمكن\\s+الشفاء\\s+من\\s+(\\S+)\",\n",
    "                r\"بعد\\s+تناول\\s+(\\S+)\\s+تتحسن\\s+حالة\\s+(\\S+)\",\n",
    "                r\"يعطى\\s+(\\S+)\\s+لمرضى\\s+(\\S+)\",\n",
    "                r\"يوصف\\s+(\\S+)\\s+لحالات\\s+(\\S+)\",\n",
    "                r\"يؤخذ\\s+(\\S+)\\s+لعلاج\\s+(\\S+)\",\n",
    "                r\"يتم\\s+وصف\\s+(\\S+)\\s+ل\\s+(\\S+)\",\n",
    "                r\"يقدم\\s+(\\S+)\\s+للمصابين\\s+ب\\s+(\\S+)\",\n",
    "                r\"يجرى\\s+علاج\\s+(\\S+)\\s+ب\\s+(\\S+)\",\n",
    "                r\"تحت\\s+اسم\\s+(\\S+)\\s+يعالج\\s+(\\S+)\",\n",
    "                r\"ضمن\\s+بروتوكول\\s+(\\S+)\\s+لعلاج\\s+(\\S+)\",\n",
    "                r\"في\\s+اطار\\s+علاج\\s+(\\S+)\\s+يستخدم\\s+(\\S+)\",\n",
    "                r\"خلال\\s+معالجة\\s+(\\S+)\\s+يعطى\\s+(\\S+)\",\n",
    "                r\"عند\\s+الاصابة\\s+ب\\s+(\\S+)\\s+يوصى\\s+ب\\s+(\\S+)\",\n",
    "                r\"مع\\s+ظهور\\s+اعراض\\s+(\\S+)\\s+يعالج\\s+ب\\s+(\\S+)\",\n",
    "                r\"اثناء\\s+علاج\\s+(\\S+)\\s+يضاف\\s+(\\S+)\",\n",
    "                r\"بعد\\s+تشخيص\\s+(\\S+)\\s+يعالج\\s+ب\\s+(\\S+)\",\n",
    "                r\"قبل\\s+العمليات\\s+يعطى\\s+(\\S+)\\s+ل\\s+(\\S+)\",\n",
    "                r\"بعد\\s+الجراحة\\s+يستخدم\\s+(\\S+)\\s+ل\\s+(\\S+)\",\n",
    "                r\"في\\s+المستشفيات\\s+يعالج\\s+(\\S+)\\s+ب\\s+(\\S+)\",\n",
    "                r\"في\\s+العيادات\\s+يوصف\\s+(\\S+)\\s+ل\\s+(\\S+)\",\n",
    "                r\"اذا\\s+كنت\\s+تعاني\\s+من\\s+(\\S+)\\s+فاستخدم\\s+(\\S+)\",\n",
    "                r\"لمرضى\\s+(\\S+)\\s+ينصح\\s+ب\\s+(\\S+)\",\n",
    "                r\"لعلاج\\s+(\\S+)\\s+يستخدم\\s+(\\S+)\",\n",
    "                r\"في\\s+حالات\\s+(\\S+)\\s+يوصى\\s+ب\\s+(\\S+)\",\n",
    "                r\"عندما\\s+يصاب\\s+المرء\\s+ب\\s+(\\S+)\\s+يعالج\\s+ب\\s+(\\S+)\",\n",
    "                r\"اذا\\s+ظهر\\s+(\\S+)\\s+فالعلاج\\s+ب\\s+(\\S+)\",\n",
    "                r\"في\\s+حالة\\s+(\\S+)\\s+العلاج\\s+(\\S+)\",\n",
    "                r\"عند\\s+وجود\\s+(\\S+)\\s+يجب\\s+استخدام\\s+(\\S+)\",\n",
    "                r\"مع\\s+تشخيص\\s+(\\S+)\\s+يبدا\\s+علاج\\s+(\\S+)\",\n",
    "                r\"بمجرد\\s+الاصابة\\s+ب\\s+(\\S+)\\s+يعطى\\s+(\\S+)\",\n",
    "                r\"اذا\\s+اشتبه\\s+ب\\s+(\\S+)\\s+يعالج\\s+ب\\s+(\\S+)\",\n",
    "                r\"عند\\s+الشك\\s+في\\s+(\\S+)\\s+يوصف\\s+(\\S+)\",\n",
    "                r\"في\\s+الاشتباه\\s+ب\\s+(\\S+)\\s+يعالج\\s+ب\\s+(\\S+)\",\n",
    "                r\"اذا\\s+كان\\s+التشخيص\\s+(\\S+)\\s+فالعلاج\\s+(\\S+)\",\n",
    "                r\"عند\\s+تاكيد\\s+(\\S+)\\s+يبدا\\s+(\\S+)\",\n",
    "                r\"بعد\\s+تاكيد\\s+الاصابة\\s+ب\\s+(\\S+)\\s+يعالج\\s+ب\\s+(\\S+)\",\n",
    "                r\"مع\\s+ظهور\\s+نتائج\\s+(\\S+)\\s+يوصف\\s+(\\S+)\",\n",
    "                r\"اذا\\s+استمر\\s+(\\S+)\\s+فالعلاج\\s+(\\S+)\",\n",
    "                r\"عند\\s+تفاقم\\s+(\\S+)\\s+يستخدم\\s+(\\S+)\",\n",
    "                r\"في\\s+الحالات\\s+المستعصية\\s+من\\s+(\\S+)\\s+يعالج\\s+ب\\s+(\\S+)\"\n",
    "            ],\n",
    "\n",
    "            \"يتسبب\": [\n",
    "                r\"يؤدي\\s+(\\S+)\\s+الى\\s+(\\S+)\",\n",
    "                r\"يتسبب\\s+(\\S+)\\s+في\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+يؤدي\\s+الى\\s+حدوث\\s+(\\S+)\",\n",
    "                r\"من\\s+اثار\\s+(\\S+)\\s+الاصابة\\s+ب\\s+(\\S+)\",\n",
    "                r\"يحدث\\s+(\\S+)\\s+مرض\\s+(\\S+)\",\n",
    "                r\"ينتج\\s+عن\\s+(\\S+)\\s+ظهور\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+من\\s+مسببات\\s+(\\S+)\",\n",
    "                r\"يعرض\\s+(\\S+)\\s+للاصابة\\s+ب\\s+(\\S+)\",\n",
    "                r\"يحفز\\s+(\\S+)\\s+ظهور\\s+(\\S+)\",\n",
    "                r\"يولد\\s+(\\S+)\\s+حالة\\s+(\\S+)\",\n",
    "                r\"بسبب\\s+(\\S+)\\s+يحدث\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+يؤدي\\s+لتفاقم\\s+(\\S+)\",\n",
    "                r\"يتسبب\\s+(\\S+)\\s+في\\s+تفشي\\s+(\\S+)\",\n",
    "                r\"ينشا\\s+(\\S+)\\s+عن\\s+(\\S+)\",\n",
    "                r\"(\\S+)\\s+مصدر\\s+ل\\s+(\\S+)\",\n",
    "                r\"يورث\\s+(\\S+)\\s+مرض\\s+(\\S+)\",\n",
    "                r\"ينتج\\s+(\\S+)\\s+عن\\s+(\\S+)\",\n",
    "                r\"يسبب\\s+(\\S+)\\s+مضاعفات\\s+(\\S+)\",\n",
    "                r\"يعمل\\s+(\\S+)\\s+على\\s+احداث\\s+(\\S+)\",\n",
    "                r\"يساهم\\s+(\\S+)\\s+في\\s+ظهور\\s+(\\S+)\",\n",
    "            ],\n",
    "\n",
    "            \"يقي\": [\n",
    "                r\"يقي\\s+(\\S+)\\s+من\\s+(\\S+)\",\n",
    "                r\"يحمي\\s+(\\S+)\\s+من\\s+الاصابة\\s+ب\\s+(\\S+)\",\n",
    "                r\"يمنع\\s+(\\S+)\\s+حدوث\\s+(\\S+)\",\n",
    "                r\"يحصن\\s+(\\S+)\\s+ضد\\s+(\\S+)\",\n",
    "                r\"يقي\\s+(\\S+)\\s+من\\s+خطر\\s+(\\S+)\",\n",
    "                r\"يبعد\\s+(\\S+)\\s+شبح\\s+(\\S+)\",\n",
    "                r\"يمنع\\s+(\\S+)\\s+تطور\\s+(\\S+)\",\n",
    "                r\"يحول\\s+(\\S+)\\s+دون\\s+(\\S+)\",\n",
    "                r\"يقي\\s+(\\S+)\\s+من\\s+مضاعفات\\s+(\\S+)\",\n",
    "                r\"يقلل\\s+(\\S+)\\s+من\\s+احتمالية\\s+(\\S+)\",\n",
    "                r\"يجنب\\s+(\\S+)\\s+الاصابة\\s+ب\\s+(\\S+)\",\n",
    "                r\"يمنع\\s+(\\S+)\\s+انتشار\\s+(\\S+)\",\n",
    "                r\"يحافظ\\s+(\\S+)\\s+على\\s+الوقاية\\s+من\\s+(\\S+)\",\n",
    "                r\"يسهم\\s+(\\S+)\\s+في\\s+منع\\s+(\\S+)\",\n",
    "                r\"يضاد\\s+(\\S+)\\s+حدوث\\s+(\\S+)\",\n",
    "                r\"يعيق\\s+(\\S+)\\s+تقدم\\s+(\\S+)\",\n",
    "                r\"يحبط\\s+(\\S+)\\s+ظهور\\s+(\\S+)\",\n",
    "                r\"يقاوم\\s+(\\S+)\\s+نشوء\\s+(\\S+)\",\n",
    "                r\"يشكل\\s+(\\S+)\\s+حاجزا\\s+ضد\\s+(\\S+)\",\n",
    "                r\"يساعد\\s+(\\S+)\\s+في\\s+تجنب\\s+(\\S+)\",\n",
    "            ],\n",
    "\n",
    "            \"يزيد\": [\n",
    "                r\"يزيد\\s+(\\S+)\\s+من\\s+(\\S+)\",\n",
    "                r\"يرفع\\s+(\\S+)\\s+مستوى\\s+(\\S+)\",\n",
    "                r\"يعزز\\s+(\\S+)\\s+من\\s+(\\S+)\",\n",
    "                r\"يضاعف\\s+(\\S+)\\s+خطر\\s+(\\S+)\",\n",
    "                r\"يكثف\\s+(\\S+)\\s+من\\s+(\\S+)\",\n",
    "                r\"يعظم\\s+(\\S+)\\s+من\\s+(\\S+)\",\n",
    "                r\"يضخم\\s+(\\S+)\\s+تاثير\\s+(\\S+)\",\n",
    "                r\"يسرع\\s+(\\S+)\\s+من\\s+(\\S+)\",\n",
    "                r\"يحفز\\s+(\\S+)\\s+زيادة\\s+(\\S+)\",\n",
    "                r\"يشجع\\s+(\\S+)\\s+على\\s+(\\S+)\",\n",
    "                r\"يعلي\\s+(\\S+)\\s+من\\s+(\\S+)\",\n",
    "                r\"يقوي\\s+(\\S+)\\s+من\\s+(\\S+)\",\n",
    "                r\"ينمي\\s+(\\S+)\\s+(\\S+)\",\n",
    "                r\"يضاعف\\s+(\\S+)\\s+فرص\\s+(\\S+)\",\n",
    "                r\"يعزز\\s+(\\S+)\\s+ظهور\\s+(\\S+)\",\n",
    "                r\"يحرض\\s+(\\S+)\\s+على\\s+(\\S+)\",\n",
    "                r\"يسرع\\s+(\\S+)\\s+وتيرة\\s+(\\S+)\",\n",
    "                r\"يعظم\\s+(\\S+)\\s+حجم\\s+(\\S+)\",\n",
    "                r\"يكسب\\s+(\\S+)\\s+قوة\\s+(\\S+)\",\n",
    "                r\"يضيف\\s+(\\S+)\\s+الى\\s+(\\S+)\",\n",
    "            ],\n",
    "\n",
    "            \"يقلل\": [\n",
    "                r\"يقلل\\s+(\\S+)\\s+من\\s+(\\S+)\",\n",
    "                r\"يخفض\\s+(\\S+)\\s+مستوى\\s+(\\S+)\",\n",
    "                r\"يحد\\s+(\\S+)\\s+من\\s+(\\S+)\",\n",
    "                r\"يضعف\\s+(\\S+)\\s+(\\S+)\",\n",
    "                r\"يخمد\\s+(\\S+)\\s+(\\S+)\",\n",
    "                r\"يثبط\\s+(\\S+)\\s+من\\s+(\\S+)\",\n",
    "                r\"يقلص\\s+(\\S+)\\s+حجم\\s+(\\S+)\",\n",
    "                r\"يخفض\\s+(\\S+)\\s+نسبة\\s+(\\S+)\",\n",
    "                r\"يعيق\\s+(\\S+)\\s+(\\S+)\",\n",
    "                r\"يبطئ\\s+(\\S+)\\s+من\\s+(\\S+)\",\n",
    "                r\"يخفف\\s+(\\S+)\\s+من\\s+(\\S+)\",\n",
    "                r\"يحد\\s+(\\S+)\\s+من\\s+انتشار\\s+(\\S+)\",\n",
    "                r\"يضاد\\s+(\\S+)\\s+تاثير\\s+(\\S+)\",\n",
    "                r\"يخمد\\s+(\\S+)\\s+اعراض\\s+(\\S+)\",\n",
    "                r\"يقلل\\s+(\\S+)\\s+حدة\\s+(\\S+)\",\n",
    "                r\"يخفض\\s+(\\S+)\\s+معدل\\s+(\\S+)\",\n",
    "                r\"يضعف\\s+(\\S+)\\s+شدة\\s+(\\S+)\",\n",
    "                r\"يثبط\\s+(\\S+)\\s+تقدم\\s+(\\S+)\",\n",
    "                r\"يحجم\\s+(\\S+)\\s+نطاق\\s+(\\S+)\",\n",
    "                r\"يخمد\\s+(\\S+)\\s+تفاقم\\s+(\\S+)\",\n",
    "            ],\n",
    "\n",
    "            \"يتفاعل\": [\n",
    "                r\"يتفاعل\\s+(\\S+)\\s+مع\\s+(\\S+)\",\n",
    "                r\"يتاثر\\s+(\\S+)\\s+و\\s+(\\S+)\",\n",
    "                r\"يتداخل\\s+(\\S+)\\s+مع\\s+(\\S+)\",\n",
    "                r\"يؤثر\\s+(\\S+)\\s+على\\s+(\\S+)\",\n",
    "                r\"يتعارض\\s+(\\S+)\\s+مع\\s+(\\S+)\",\n",
    "                r\"يتكامل\\s+(\\S+)\\s+مع\\s+(\\S+)\",\n",
    "                r\"يتضاد\\s+(\\S+)\\s+مع\\s+(\\S+)\",\n",
    "                r\"يتناغم\\s+(\\S+)\\s+مع\\s+(\\S+)\",\n",
    "                r\"يتعارك\\s+(\\S+)\\s+مع\\s+(\\S+)\",\n",
    "                r\"يتلاقى\\s+(\\S+)\\s+مع\\s+(\\S+)\",\n",
    "                r\"يتاثر\\s+(\\S+)\\s+مع\\s+(\\S+)\",\n",
    "                r\"يتنافر\\s+(\\S+)\\s+مع\\s+(\\S+)\",\n",
    "                r\"يتزامن\\s+(\\S+)\\s+مع\\s+(\\S+)\",\n",
    "                r\"يتقاطع\\s+(\\S+)\\s+مع\\s+(\\S+)\",\n",
    "                r\"يتحد\\s+(\\S+)\\s+مع\\s+(\\S+)\",\n",
    "                r\"يندمج\\s+(\\S+)\\s+مع\\s+(\\S+)\",\n",
    "                r\"يتعارض\\s+(\\S+)\\s+مع\\s+مفعول\\s+(\\S+)\",\n",
    "                r\"يتعاضد\\s+(\\S+)\\s+مع\\s+(\\S+)\",\n",
    "                r\"يتنافس\\s+(\\S+)\\s+مع\\s+(\\S+)\",\n",
    "                r\"يتالف\\s+(\\S+)\\s+مع\\s+(\\S+)\",\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "        return templates\n",
    "    \n",
    "    def extract_noun_phrases(self, tagged_sentence: List[Tuple[str, str]]) -> List[str]:\n",
    "        noun_phrases = []\n",
    "        current_phrase = []\n",
    "        \n",
    "        for word, tag in tagged_sentence:\n",
    "            if tag.startswith('NN'):\n",
    "                current_phrase.append(word)\n",
    "            elif tag.startswith('JJ'):\n",
    "                current_phrase.append(word)\n",
    "            elif tag.startswith('DT'):\n",
    "                current_phrase.append(word)\n",
    "            else:\n",
    "                if current_phrase:\n",
    "                    noun_phrases.append(' '.join(current_phrase))\n",
    "                    current_phrase = []\n",
    "        \n",
    "        if current_phrase:\n",
    "            noun_phrases.append(' '.join(current_phrase))\n",
    "            \n",
    "        return noun_phrases\n",
    "    \n",
    "    def is_medical_entity(self, entity: str, tagged_sentence: List[Tuple[str, str]]) -> bool:\n",
    "        drug_indicators = ['دواء', 'عقار', 'علاج', 'مضاد', 'حبوب', 'كبسولة', 'حقنة']\n",
    "        \n",
    "        disease_indicators = ['مرض', 'داء', 'عدوى', 'التهاب', 'سرطان', 'سكري', 'ضغط']\n",
    "        \n",
    "        entity_lower = entity.lower()\n",
    "        \n",
    "        for indicator in drug_indicators + disease_indicators:\n",
    "            if indicator in entity_lower:\n",
    "                return True\n",
    "        \n",
    "        for word, tag in tagged_sentence:\n",
    "            if word in entity:\n",
    "                if tag in ['NN', 'NNP']:\n",
    "                    return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def extract_relations_from_text(self, text: str) -> List[Dict[str, Any]]:\n",
    "        relations = []\n",
    "        \n",
    "        try:\n",
    "            tagged = self.tagger.tag_text(text)\n",
    "            if isinstance(tagged, str):\n",
    "                return relations\n",
    "            \n",
    "            noun_phrases = self.extract_noun_phrases(tagged)\n",
    "            \n",
    "            for relation_type, patterns in self.templates.items():\n",
    "                for pattern in patterns:\n",
    "                    matches = re.finditer(pattern, text)\n",
    "                    \n",
    "                    for match in matches:\n",
    "                        if len(match.groups()) >= 2:\n",
    "                            x_entity = match.group(1).strip()\n",
    "                            y_entity = match.group(2).strip()\n",
    "                            \n",
    "                            if (self.is_medical_entity(x_entity, tagged) and \n",
    "                                self.is_medical_entity(y_entity, tagged)):\n",
    "                                \n",
    "                                relation = {\n",
    "                                    'relation_type': relation_type,\n",
    "                                    'x_entity': x_entity,\n",
    "                                    'y_entity': y_entity,\n",
    "                                    'pattern': pattern,\n",
    "                                    'source_text': text[:100] + \"...\" if len(text) > 100 else text,\n",
    "                                    'noun_phrases': noun_phrases,\n",
    "                                }\n",
    "                                \n",
    "                                relations.append(relation)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"ُError in relation extraction: {e}\")\n",
    "            \n",
    "        return relations\n",
    "    \n",
    "    def process_dataframe(self, df: pd.DataFrame, text_column: str = 'articleBody') -> pd.DataFrame:\n",
    "        all_relations = []\n",
    "        \n",
    "        print(f\"Start extracting realtions from {len(df)} articles...\")\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            text = row[text_column]\n",
    "            \n",
    "            if pd.notna(text) and text.strip():\n",
    "                relations = self.extract_relations_from_text(str(text))\n",
    "                \n",
    "                for relation in relations:\n",
    "                    relation['article_id'] = idx\n",
    "                    relation['headline'] = row.get('headline', '')\n",
    "                    relation['link'] = row.get('link', '')\n",
    "                    all_relations.append(relation)\n",
    "            \n",
    "            if (idx + 1) % 100 == 0:\n",
    "                print(f\"article {idx + 1} processed...\")\n",
    "        \n",
    "        results_df = pd.DataFrame(all_relations)\n",
    "        \n",
    "        print(f\"{len(results_df)} relation extracted from articles\")\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    def save_results(self, results_df: pd.DataFrame, filename: str = \"extracted_relations\"):\n",
    "        results_path = f\"{self.base_dir}/results/{filename}.csv\"\n",
    "        results_df.to_csv(results_path, index=False, encoding='utf-8')\n",
    "        print(f\"results saved in: {results_path}\")\n",
    "        \n",
    "        json_path = f\"{self.base_dir}/results/{filename}.json\"\n",
    "        results_df.to_json(json_path, orient='records', force_ascii=False, indent=2)\n",
    "        print(f\"Results json copy {json_path}\")\n",
    "        \n",
    "        stats = self.calculate_statistics(results_df)\n",
    "        stats_path = f\"{self.base_dir}/results/{filename}_stats.json\"\n",
    "        with open(stats_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(stats, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"Saving statistics {stats_path}\")\n",
    "        \n",
    "        return results_path\n",
    "    \n",
    "    def calculate_statistics(self, results_df: pd.DataFrame) -> Dict[str, Any]:\n",
    "        if results_df.empty:\n",
    "            return {}\n",
    "            \n",
    "        stats = {\n",
    "            'total_relations': len(results_df),\n",
    "            'relations_by_type': results_df['relation_type'].value_counts().to_dict(),\n",
    "            'average_confidence': results_df['confidence'].mean(),\n",
    "            'articles_with_relations': results_df['article_id'].nunique(),\n",
    "            'top_x_entities': results_df['x_entity'].value_counts().head(10).to_dict(),\n",
    "            'top_y_entities': results_df['y_entity'].value_counts().head(10).to_dict(),\n",
    "            'most_common_patterns': results_df['pattern'].value_counts().head(5).to_dict()\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "\n",
    "class ArabicPOSTagger:\n",
    "    def __init__(self):\n",
    "        self.model = './content/drive/MyDrive/stanford-postagger-full/models/arabic.tagger'\n",
    "        self.jar = './content/drive/MyDrive/stanford-postagger-full/stanford-postagger.jar'\n",
    "        self.tagger = None\n",
    "        self.initialize_tagger()\n",
    "    \n",
    "    def initialize_tagger(self):\n",
    "        try:\n",
    "            self.tagger = StanfordPOSTagger(\n",
    "                model_filename=self.model,\n",
    "                path_to_jar=self.jar,\n",
    "                encoding='utf-8'\n",
    "            )\n",
    "            print(\"Stanford POS Tagger initialized successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to initialize Stanford POS Tagger: {e}\")\n",
    "            self.tagger = None\n",
    "    \n",
    "    def tag_text(self, text: str):\n",
    "        if self.tagger is None:\n",
    "            return f\"Error: Tagger not initialized\"\n",
    "        \n",
    "        try:\n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            tagged_words = self.tagger.tag(words)\n",
    "            \n",
    "            return tagged_words\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error in POS tagging: {e}\"\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        processed_data_path = \"./data/processed/medical_corpus_processed.json\"\n",
    "        df = pd.read_json(processed_data_path)\n",
    "        print(f\"{len(df)} articles were loaded.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Dataset not found!\")\n",
    "        return\n",
    "    \n",
    "    extractor = RelationExtractor()\n",
    "    \n",
    "    results_df = extractor.process_dataframe(df)\n",
    "    \n",
    "    if not results_df.empty:\n",
    "        extractor.save_results(results_df)\n",
    "        \n",
    "        print(\"Sample of the extracted relations:\")\n",
    "        print(results_df[['relation_type', 'x_entity', 'y_entity', 'confidence']].head(10))\n",
    "        \n",
    "        stats = extractor.calculate_statistics(results_df)\n",
    "        print(f\"Statistics\")\n",
    "        print(f\"   Total relations: {stats['total_relations']}\")\n",
    "        print(f\"   # articls with relations: {stats['articles_with_relations']}\")\n",
    "        print(f\"   relations distribution: {stats['relations_by_type']}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"No relation were extracted\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anlp-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
